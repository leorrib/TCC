{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b32091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Project root detected as: /Users/leonardoribeiro/Documents/DataScience/MBA_USP/TCC\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 04_GIN_embeddings.ipynb\n",
    "# Pr√©-treinamento contrastivo com GIN (GCPAL-like)\n",
    "# ==========================================================\n",
    "\n",
    "# 0) Project setup (path fix for notebooks)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect project root (works in notebooks and scripts)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    ROOT = Path.cwd().parents[0]  # assumes this notebook lives in /notebooks\n",
    "\n",
    "# Add project root to sys.path so `src` can be imported (if needed)\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "print(f\"üìÅ Project root detected as: {ROOT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55397204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Active device: cpu\n",
      "GPU detected: None\n",
      "Torch version: 2.8.0\n",
      "device: cpu\n",
      "data_processed: /Users/leonardoribeiro/Documents/DataScience/MBA_USP/TCC/data/processed\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Imports + config + device\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "from src.utils import ConfigLoader, EnvironmentSetup\n",
    "from src.models.gcpal import (\n",
    "    PretrainGraphBuilder,\n",
    "    build_knn_edge_index,\n",
    "    GINEncoder,\n",
    "    ProjectionHead,\n",
    "    build_positive_lists,\n",
    "    GINPretrainer,\n",
    ")\n",
    "\n",
    "# config & device\n",
    "cfg = ConfigLoader.load(\"base.yaml\")\n",
    "env = EnvironmentSetup(seed=cfg.get(\"general\", {}).get(\"seed\", 42))\n",
    "device = env.device\n",
    "print(\"device:\", device)\n",
    "\n",
    "data_proc = (ROOT / cfg[\"paths\"][\"data_processed\"]).resolve()\n",
    "print(\"data_processed:\", data_proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8445c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes_with_class: (203769, 168)\n",
      "edges: (234355, 2)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Carrega CSVs processados do 01/03\n",
    "# ==========================================================\n",
    "nodes_with_class_path = data_proc / \"elliptic_nodes_with_class.csv\"\n",
    "edges_path            = data_proc / \"elliptic_edges.csv\"\n",
    "\n",
    "df_nodes_with_class = pd.read_csv(nodes_with_class_path)\n",
    "df_edges            = pd.read_csv(edges_path)\n",
    "\n",
    "print(\"nodes_with_class:\", df_nodes_with_class.shape)\n",
    "print(\"edges:\", df_edges.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa329d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[136265, 165], edge_index=[2, 313686], y=[136265], mask_labeled=[136265])\n",
      "Total de n√≥s (‚â§34): 136265\n",
      "Total de arestas (bidirecionais): 313686\n",
      "N√≥s rotulados: 29894\n",
      "Propor√ß√£o de il√≠citos nos rotulados: 0.11580919474363327\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Grafo √öNICO de pr√©-treino (time_step <= 34) com PretrainGraphBuilder\n",
    "# ==========================================================\n",
    "feature_cols = [c for c in df_nodes_with_class.columns if c.startswith(\"feature_\")]\n",
    "\n",
    "pt_builder = PretrainGraphBuilder(\n",
    "    df_nodes_with_class=df_nodes_with_class,\n",
    "    df_edges=df_edges,\n",
    "    feature_cols=feature_cols,\n",
    "    max_train_step=cfg.get(\"pretrain\", {}).get(\"max_train_step\", 34),\n",
    "    device=device,\n",
    ")\n",
    "data_train_global = pt_builder.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48aef112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index_knn: (2, 4087992)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# KNN view (k=15 por padr√£o, pode vir do YAML)\n",
    "# ==========================================================\n",
    "k = cfg.get(\"pretrain\", {}).get(\"k\", 15)\n",
    "knn_bs = cfg.get(\"pretrain\", {}).get(\"knn_batch_size\", 4096)\n",
    "\n",
    "edge_index_knn = build_knn_edge_index(\n",
    "    x=data_train_global.x.to(device),\n",
    "    k=k,\n",
    "    batch_size=knn_bs,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"edge_index_knn:\", tuple(edge_index_knn.size()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d7ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder/proj prontos: 165 128 2 128\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Modelo: GINEncoder + ProjectionHead\n",
    "# ==========================================================\n",
    "in_dim      = data_train_global.x.size(1)\n",
    "hidden_dim  = cfg.get(\"model\", {}).get(\"gin\", {}).get(\"hidden_dim\", 128)\n",
    "layers      = cfg.get(\"model\", {}).get(\"gin\", {}).get(\"layers\", 2)\n",
    "proj_dim    = cfg.get(\"model\", {}).get(\"gin\", {}).get(\"proj_dim\", 128)\n",
    "\n",
    "encoder  = GINEncoder(in_channels=in_dim, hidden_channels=hidden_dim, num_layers=layers).to(device)\n",
    "proj_head = ProjectionHead(in_dim=hidden_dim, proj_dim=proj_dim).to(device)\n",
    "\n",
    "print(\"encoder/proj prontos:\", in_dim, hidden_dim, layers, proj_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebef763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136265, 136265)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Listas de positivos (A estrutural e A_KNN)\n",
    "# ==========================================================\n",
    "pos_lists_struct = build_positive_lists(\n",
    "    edge_index=data_train_global.edge_index.to(\"cpu\"),\n",
    "    num_nodes=data_train_global.num_nodes,\n",
    "    add_self=True,\n",
    ")\n",
    "pos_lists_knn = build_positive_lists(\n",
    "    edge_index=edge_index_knn.to(\"cpu\"),\n",
    "    num_nodes=data_train_global.num_nodes,\n",
    "    add_self=True,\n",
    ")\n",
    "\n",
    "len(pos_lists_struct), len(pos_lists_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f654ad21",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      4\u001b[39m pre = cfg.get(\u001b[33m\"\u001b[39m\u001b[33mpretrain\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m      6\u001b[39m trainer = GINPretrainer(\n\u001b[32m      7\u001b[39m     device=device,\n\u001b[32m      8\u001b[39m     lambda_mix=pre.get(\u001b[33m\"\u001b[39m\u001b[33mlambda_mix\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.5\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     drop_p_feat=pre.get(\u001b[33m\"\u001b[39m\u001b[33mdrop_p_feat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.3\u001b[39m),\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m metrics = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_train_global\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_train_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index_knn\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_index_knn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproj_head\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproj_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpos_lists_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_lists_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpos_lists_knn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_lists_knn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/MBA_USP/TCC/src/models/gcpal/trainer.py:63\u001b[39m, in \u001b[36mGINPretrainer.fit\u001b[39m\u001b[34m(self, data_train_global, edge_index_knn, encoder, proj_head, pos_lists_struct, pos_lists_knn)\u001b[39m\n\u001b[32m     60\u001b[39m     z2 = proj_head(h2)\n\u001b[32m     61\u001b[39m     z_knn = proj_head(h_knn)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m loss_rand = \u001b[43mcontrastive_loss_tiled\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mz1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_lists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_lists_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43manchor_bs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43manchor_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_bs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m loss_knn = contrastive_loss_tiled(\n\u001b[32m     68\u001b[39m     z1, z_knn, pos_lists=pos_lists_knn, tau=\u001b[38;5;28mself\u001b[39m.tau,\n\u001b[32m     69\u001b[39m     anchor_bs=\u001b[38;5;28mself\u001b[39m.anchor_bs, target_bs=\u001b[38;5;28mself\u001b[39m.target_bs, device=\u001b[38;5;28mself\u001b[39m.device\n\u001b[32m     70\u001b[39m )\n\u001b[32m     72\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.lambda_mix * loss_rand + (\u001b[32m1\u001b[39m - \u001b[38;5;28mself\u001b[39m.lambda_mix) * loss_knn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DataScience/MBA_USP/TCC/src/models/gcpal/contrastive_loss.py:45\u001b[39m, in \u001b[36mcontrastive_loss_tiled\u001b[39m\u001b[34m(z_anchor, z_target, pos_lists, tau, anchor_bs, target_bs, device)\u001b[39m\n\u001b[32m     43\u001b[39m sim_chunk = torch.matmul(za, zt.t()) / tau\n\u001b[32m     44\u001b[39m sim_chunk = sim_chunk - global_max\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m exp_chunk = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m denom = denom + exp_chunk.sum(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# positives in this chunk\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Treino contrastivo com GINPretrainer (mesma l√≥gica do seu loop)\n",
    "# ==========================================================\n",
    "pre = cfg.get(\"pretrain\", {})\n",
    "\n",
    "trainer = GINPretrainer(\n",
    "    device=device,\n",
    "    lambda_mix=pre.get(\"lambda_mix\", 0.5),\n",
    "    tau=pre.get(\"tau\", 0.5),\n",
    "    lr=pre.get(\"lr\", 1e-3),\n",
    "    max_epochs=pre.get(\"epochs\", 20),\n",
    "    anchor_bs=pre.get(\"anchor_bs\", 2048),\n",
    "    target_bs=pre.get(\"target_bs\", 32768),\n",
    "    patience=pre.get(\"patience\", 999),\n",
    "    drop_p_edge=pre.get(\"drop_p_edge\", 0.3),\n",
    "    drop_p_feat=pre.get(\"drop_p_feat\", 0.3),\n",
    ")\n",
    "\n",
    "metrics = trainer.fit(\n",
    "    data_train_global=data_train_global,\n",
    "    edge_index_knn=edge_index_knn,\n",
    "    encoder=encoder,\n",
    "    proj_head=proj_head,\n",
    "    pos_lists_struct=pos_lists_struct,\n",
    "    pos_lists_knn=pos_lists_knn,\n",
    ")\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Export GCPAL embeddings (raw + optional PCA) to CSVs\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.models.gcpal import SafeSplitBuilder, EmbeddingExporter\n",
    "\n",
    "# 1) Ranges & paths\n",
    "s = cfg[\"splits\"]\n",
    "data_proc = (ROOT / cfg[\"paths\"][\"data_processed\"]).resolve()\n",
    "splits_dir = data_proc / \"splits\"\n",
    "emb_dir = data_proc / \"embeddings\"\n",
    "\n",
    "# 2) Load labeled tabular splits (saved in 03)\n",
    "df_train = pd.read_csv(splits_dir / \"train_nodes.csv\")\n",
    "df_test1 = pd.read_csv(splits_dir / \"test1_nodes.csv\")\n",
    "df_test2 = pd.read_csv(splits_dir / \"test2_nodes.csv\")\n",
    "\n",
    "# 3) Build safe PyG splits (local contiguous indexing)\n",
    "feature_cols = [c for c in df_nodes_with_class.columns if c.startswith(\"feature_\")]\n",
    "split_builder = SafeSplitBuilder(df_nodes_with_class, df_edges, feature_cols)\n",
    "data_train, data_test1_split, data_test2_split = split_builder.build_train_test_splits(\n",
    "    train_lo=1, train_hi=s[\"train_upper\"],\n",
    "    test1_lo=s[\"test1_lower\"], test1_hi=s[\"test1_upper\"],\n",
    "    test2_lo=s[\"test2_lower\"], test2_hi=s[\"test2_upper\"],\n",
    ")\n",
    "\n",
    "# 4) Extract embeddings with safe GPU‚ÜíCPU fallback\n",
    "E_train  = EmbeddingExporter.extract_H_safe(encoder, data_train,       device)\n",
    "E_test1  = EmbeddingExporter.extract_H_safe(encoder, data_test1_split, device)\n",
    "E_test2  = EmbeddingExporter.extract_H_safe(encoder, data_test2_split, device)\n",
    "\n",
    "# 5) DataFrames (emb_gcpal_*, + txId)\n",
    "emb_train_df, emb_test1_df, emb_test2_df = EmbeddingExporter.to_dataframes(\n",
    "    E_train, E_test1, E_test2,\n",
    "    data_train, data_test1_split, data_test2_split,\n",
    ")\n",
    "\n",
    "# 6) Merge with labeled splits\n",
    "df_train_emb, df_test1_emb, df_test2_emb, df_test_emb = EmbeddingExporter.merge_with_splits(\n",
    "    df_train, df_test1, df_test2,\n",
    "    emb_train_df, emb_test1_df, emb_test2_df,\n",
    ")\n",
    "\n",
    "# 7) Optional PCA on embeddings (fit on train, transform test)\n",
    "n_comp = cfg.get(\"pretrain\", {}).get(\"pca_components\", 30)\n",
    "E_train_pca, pca = EmbeddingExporter.pca_fit_transform(E_train, n_components=n_comp, random_state=cfg.get(\"general\", {}).get(\"seed\", 42))\n",
    "E_test1_pca = EmbeddingExporter.pca_transform(pca, E_test1)\n",
    "E_test2_pca = EmbeddingExporter.pca_transform(pca, E_test2)\n",
    "\n",
    "df_train_pca, df_test1_pca, df_test2_pca = EmbeddingExporter.pca_dataframes(\n",
    "    E_train_pca, E_test1_pca, E_test2_pca,\n",
    "    data_train, data_test1_split, data_test2_split,\n",
    ")\n",
    "\n",
    "# 8) Save CSVs (filenames already include *_gcpal)\n",
    "EmbeddingExporter.save_csvs(\n",
    "    out_dir=emb_dir,\n",
    "    df_train_emb=df_train_emb,\n",
    "    df_test1_emb=df_test1_emb,\n",
    "    df_test2_emb=df_test2_emb,\n",
    "    df_train_pca=df_train_pca,\n",
    "    df_test1_pca=df_test1_pca,\n",
    "    df_test2_pca=df_test2_pca,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Embeddings salvos em:\", emb_dir.resolve())\n",
    "print(\"   -\", \"train_embeddings_gcpal.csv\")\n",
    "print(\"   -\", \"test1_embeddings_gcpal.csv\")\n",
    "print(\"   -\", \"test2_embeddings_gcpal.csv\")\n",
    "print(\"   -\", \"train_embeddings_pca_gcpal.csv\")\n",
    "print(\"   -\", \"test1_embeddings_pca_gcpal.csv\")\n",
    "print(\"   -\", \"test2_embeddings_pca_gcpal.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
